# Тестовое от [KazanExpress](https://kazanexpress.ru/)!

Для того чтобы проследить за ходом мыслей в исследовании лучше смотреть файлы в следующем порядке:

1. 0 EDA_v1.0.ipynb
2. 1 feature_generation_v2.0.ipynb
3. 2_vgg16_fine_tune_v2.0.ipynb
4. 3 img_to_text_v3.0.ipynb
5. 4 trainer_and_inference_v1.0.ipynb

Каждый файл в начале содержит небольшое описание для чего он и как (какую) задачу решает.

Файл Log_for_me.txt содержит порядок проведенных экспериментов, хотя это было несколько хаотично.

Веса итоговой модели сохранены в файле model.torch.


# Пост анализ работы:

Решение занявшее [3 место](https://github.com/PolushinM/Marketplace_product_classification)

Основные ошибки, можно использовать как [чек-лист](https://www.notion.so/03864a1cbf0847c3b4b20a16f44ce98f?pvs=4)

Провел анализ кода одного из лидеров и приведенных частых ошибок организаторами, извлек для себя:
- Вначале исследования сосредоточится на проведении EDA - осмыленного и читабельного
- Добавлять в каждое исследование файл requirements.txt
- Очень важна описательная часть исследования - readme.md с подробным описанием структуры и хода исследования, умеренное количество комментариев по тексту ноутбука чтобы не терять ход мыслей исследователя
- После EDA задать какой-то простой baseline который в дальнейшем исследовании послужит benchmark-ом
- Полезно в структуру исследования добавить 1) обзор литературы по теме 2) тестирование нескольких подходов к решению 3) постанализ результатов
- Код по фиксации случайности на всем исследовании
- Вспомнил про практику применения fasttext для классификации текстов из коробки
- познакомился с библиотекой multiprocessing и ее применением в num_workers
- Обратил внимание как использовать класс CFG в рукописной функции, помещаем в переменные функции весь класс
- Практика взятия last_hidden_state из моделей HF https://docs.arize.com/arize/embeddings/how-to-generate-your-own-embedding
- Познакомился с назначением функции collate_fn, преподготовка данных внутри Dataloader
- Увидел практический пример как запомнить и сохранить лучшую эпоху в процессе обучения
- Увидел практический пример создания рукописных checkpoint-ов в PyTorch через state_dict()
- Увидел пример рукописного grid_search для моделей в PyTorch
- Чуть лучше разобрался с scheduler_lr в PyTorch
- Увидел пример практического использования простого рукописного Attention, хотя не до конца понял практическую полезность испльзования его здесь
- Узнал о мультимодальное модели CLIP (эмбеддинги из картинки), и увидел пример взятия эмбеддингов из этой модели
